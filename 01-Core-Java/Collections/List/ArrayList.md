# ğŸ“˜ Complete Java ArrayList Reference

### 1ï¸âƒ£ Overview
* **ğŸ§  Theory:** `ArrayList` is a resizable array implementation of the `List` interface present in `java.util`. It maintains insertion order, allows duplicates, provides fast random access, and is **not thread-safe**.

### 2ï¸âƒ£ Class Hierarchy
* **ğŸ§  Theory:** It implements `List<E>`, `RandomAccess` (marker for fast retrieval), `Cloneable`, and `Serializable`.
* **ğŸ’» Code (Architecture):**
  ```text
  Object
    â†³ AbstractCollection<E>
         â†³ AbstractList<E>
              â†³ ArrayList<E>

```

### 3ï¸âƒ£ Internal Data Structure

* **ğŸ§  Theory:** Internally backed by a dynamic array. `Capacity` is the total allocated length, while `size` is the number of elements actually stored. Default initial capacity is 10.

* **ğŸ’» Code:**
```java
transient Object[] elementData; // The underlying array
private int size;               // Number of elements stored

```

### 4ï¸âƒ£ Constructors

* **ğŸ§  Theory:** You can initialize it empty, with a pre-defined capacity to save memory overhead, or by copying another collection.
* **ğŸ’» Code:**
```java
// 1. Default (Capacity 10)
ArrayList<Integer> list = new ArrayList<>();

// 2. Initial Capacity (Avoids resizing overhead)
ArrayList<Integer> list = new ArrayList<>(20);

// 3. From Collection
ArrayList<String> list = new ArrayList<>(existingCollection);

```

### 5ï¸âƒ£ Resizing Mechanism (Very Important)

* **ğŸ§  Theory:** When capacity is exceeded, it creates a new array, copies the old elements over (`O(n)` time), and grows by **1.5x**.
* **ğŸ’» Code:**
```java
// Internal growth formula using a bitwise shift
newCapacity = oldCapacity + (oldCapacity >> 1)

```

*(Example: 10 â†’ 15 â†’ 22 â†’ 33)*

### 6ï¸âƒ£ Time Complexity

* **ğŸ§  Theory:** Adding elements is generally instant, but occasionally triggers a resize, making it an "amortized" cost. Searching requires a linear scan.
* **ğŸ’» Code (Operations):**
* `get(index)` / `set(index)` â†’ **O(1)**
* `add(E e)` â†’ **O(1)** amortized
* `add(index, e)` / `remove(index)` â†’ **O(n)**
* `contains()` â†’ **O(n)**


### 7ï¸âƒ£ Fail-Fast Behavior

* **ğŸ§  Theory:** `ArrayList` uses an internal `modCount` to track structural changes. Modifying the list during a standard loop breaks this count and throws an error.
* **ğŸ’» Code:**
```java
// âŒ BAD: Throws ConcurrentModificationException
for(Integer i : list) {
    list.add(100); 
}

// âœ… GOOD: Safe deletion using Iterator
Iterator<Integer> it = list.iterator();
while(it.hasNext()) {
    if(it.next() == 5) {
        it.remove(); 
    }
}

```

### 8ï¸âƒ£ Thread Safety

* **ğŸ§  Theory:** `ArrayList` is strictly single-threaded. For concurrent access, you must use a wrapper or a specialized concurrent collection.
* **ğŸ’» Code:**
```java
// Option 1: Synchronized Wrapper (Requires synchronized block on iteration)
List<Integer> list = Collections.synchronizedList(new ArrayList<>());

// Option 2: Concurrent Collection (Great for read-heavy systems)
List<Integer> list = new CopyOnWriteArrayList<>();

```

### 9ï¸âƒ£ Capacity vs Size

* **ğŸ§  Theory:** `size()` returns populated slots; `capacity` is the hidden array length. You can manually manipulate capacity to optimize memory.
* **ğŸ’» Code:**
```java
list.ensureCapacity(100); // Forces growth to 100 before bulk additions
list.trimToSize();        // Shrinks underlying array to match current size

```

### ğŸ”Ÿ RandomAccess Marker Interface

* **ğŸ§  Theory:** `ArrayList` implements `RandomAccess`. This acts as a marker telling the JVM and other frameworks that this class is optimized for fast, constant-time `O(1)` random access. *(Note: `LinkedList` does NOT implement this).* 

### 1ï¸âƒ£1ï¸âƒ£ Memory Behavior

* **ğŸ§  Theory:** Stores object *references*, not primitives. Because it uses a contiguous block of memory, it benefits from high CPU cache locality, making iterations noticeably faster than node-based structures.

### 1ï¸âƒ£2ï¸âƒ£ When to Use ArrayList

* **ğŸ§  Theory:**
âœ… Heavy read operations
âœ… Frequent random access
âœ… Append-heavy usage
âœ… When memory efficiency is required

### 1ï¸âƒ£3ï¸âƒ£ When NOT to Use

* **ğŸ§  Theory:**
âŒ Frequent middle insertions
âŒ Frequent deletions
âŒ Heavy concurrent modifications